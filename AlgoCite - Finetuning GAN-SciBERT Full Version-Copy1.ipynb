{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32998e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 10:29:19.937682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 10:29:20.057601: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-21 10:29:20.439883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-21 10:29:20.439926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-21 10:29:20.439930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, AutoConfig, get_constant_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3569424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 21 10:29:20 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   40C    P8    38W / 370W |   5039MiB / 24576MiB |      3%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1897      G   /usr/lib/xorg/Xorg                 98MiB |\r\n",
      "|    0   N/A  N/A      2364      G   /usr/bin/gnome-shell               24MiB |\r\n",
      "|    0   N/A  N/A      2504      G   ...mviewer/tv_bin/TeamViewer        4MiB |\r\n",
      "|    0   N/A  N/A      3151      G   /usr/lib/firefox/firefox          141MiB |\r\n",
      "|    0   N/A  N/A     28807      C   ...krittin/newenv/bin/python     3506MiB |\r\n",
      "|    0   N/A  N/A     51043      C   ...krittin/newenv/bin/python     1254MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce813013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61dcc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdbb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed_value=42)\n",
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 256\n",
    "batch_size = 32\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.1\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = False\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 2e-5\n",
    "learning_rate_generator = 2e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 10\n",
    "multi_gpu = False\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 20\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "# ! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "# fold = 10\n",
    "# labeled_file = f\"./dataset/10-fold_original_10_percent/algocite_utilize_dataset_original_10_percent_train_fold_{fold}.csv\"\n",
    "# unlabeled_file = f\"./dataset/algocitecontexts_unlabeled_10K_random_new.csv\"\n",
    "# test_filename = f\"./dataset/10-fold_original_10_percent/algocite_utilize_dataset_original_10_percent_val_fold_{fold}.csv\"\n",
    "\n",
    "label_list = [\"UNK_UNK\", \"NOTUTILIZE\", \"UTILIZE\"]\n",
    "# label_list = [\"UNK_UNK\", 'EXTEND', 'MENTION', 'NOTALGO', 'USE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5591f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_tokens = ['<cite>']\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "tokenizer.add_tokens(citation_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0803ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(31091, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = BertModel.from_pretrained(model_name)\n",
    "transformer.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec5ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qc_examples(input_dataframe):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "\n",
    "    for idx in input_dataframe.index:\n",
    "        examples.append((input_dataframe.iloc[idx, 0], input_dataframe.iloc[idx, 1]))\n",
    "    \n",
    "    return examples\n",
    "\n",
    "def load_original_dataset(fold=1, labeled=True, mode='train', percentage=None):\n",
    "    if labeled:\n",
    "        df = pd.read_csv(f'../spin-off/dataset/fold_{fold}/10-fold_original_{percentage}/algocite_utilize_dataset_{mode}_fold_{fold}.csv')\n",
    "        df['CITATIONS_CONTEXTS'] = df['CITATIONS_CONTEXTS'].str.replace(r\"=-=[\\S\\s]+-=-\", \"<cite>\", regex=True)\n",
    "        data = get_qc_examples(df[['CITATIONS_CONTEXTS', 'UTILIZE_LABELS']])\n",
    "    else:\n",
    "        df = pd.read_csv(f'./algocitecontexts_unlabeled_10000_random_new1.csv')\n",
    "        df['LABELS'] = ['UNK_UNK']*len(df)\n",
    "        data = get_qc_examples(df[['CONTENTS', 'LABELS']])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c2c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 1\n",
    "percentage = '10_percent'\n",
    "\n",
    "train_data = load_original_dataset(fold=fold, labeled=True, mode='train', percentage=percentage)\n",
    "unlabeled_data = load_original_dataset(labeled=False)\n",
    "val_data = load_original_dataset(fold=fold, labeled=True, mode='val', percentage=percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863d665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "    '''\n",
    "    Generate a Dataloader given the input examples, eventually masked if they are \n",
    "    to be considered NOT labeled.\n",
    "    '''\n",
    "    examples = []\n",
    "\n",
    "    # Count the percentage of labeled examples  \n",
    "    num_labeled_examples = 0\n",
    "    for label_mask in label_masks:\n",
    "        if label_mask: \n",
    "            num_labeled_examples += 1\n",
    "    label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "    # if required it applies the balance\n",
    "    for index, ex in enumerate(input_examples): \n",
    "        if label_mask_rate == 1 or not balance_label_examples:\n",
    "            examples.append((ex, label_masks[index]))\n",
    "        else:\n",
    "            # IT SIMULATE A LABELED EXAMPLE\n",
    "            if label_masks[index]:\n",
    "                balance = int(1/label_mask_rate)\n",
    "                balance = int(math.log(balance,2))\n",
    "                if balance < 1:\n",
    "                    balance = 1\n",
    "                for b in range(0, int(balance)):\n",
    "                    examples.append((ex, label_masks[index]))\n",
    "            else:\n",
    "                examples.append((ex, label_masks[index]))\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # Generate input examples to the Transformer\n",
    "    #-----------------------------------------------\n",
    "    input_ids = []\n",
    "    input_mask_array = []\n",
    "    label_mask_array = []\n",
    "    label_id_array = []\n",
    "\n",
    "    # Tokenization \n",
    "    for (text, label_mask) in examples:\n",
    "        encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "        input_ids.append(encoded_sent)\n",
    "        label_id_array.append(label_map[text[1]])\n",
    "        label_mask_array.append(label_mask)\n",
    "\n",
    "    # Attention to token (to ignore padded input wordpieces)\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "        input_mask_array.append(att_mask)\n",
    "    \n",
    "    # Convertion to Tensor\n",
    "    input_ids = torch.tensor(input_ids) \n",
    "    input_mask_array = torch.tensor(input_mask_array)\n",
    "    label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "    label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "    # Building the TensorDataset\n",
    "    dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "    if do_shuffle:\n",
    "        # Compute weights for WeightedRandomSampler\n",
    "        count = Counter(label_id_array.numpy())\n",
    "#         class_count = np.array([count.get(0), count.get(1), count.get(2)])\n",
    "        class_count = np.array([count.get(idx) for idx in range(len(label_list))])\n",
    "        weight = 1./class_count\n",
    "        # print(weight)\n",
    "        samples_weight = np.array([weight[t] for t in label_id_array.numpy()])\n",
    "        samples_weight = torch.from_numpy(samples_weight)\n",
    "        # print(samples_weight)\n",
    "        sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "        \n",
    "        # sampler = RandomSampler(dataset)\n",
    "    else:\n",
    "        sampler = SequentialSampler(dataset)\n",
    "\n",
    "    # Building the DataLoader\n",
    "    return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler, \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e74363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58134/1222994171.py:57: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  label_mask_array = torch.tensor(label_mask_array)\n"
     ]
    }
   ],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "    label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = train_data\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(train_data), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "if unlabeled_data:\n",
    "    train_examples = train_examples + unlabeled_data\n",
    "    #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "    tmp_masks = np.zeros(len(unlabeled_data), dtype=bool)\n",
    "    train_label_masks = np.concatenate([train_label_masks, tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, \n",
    "                                        train_label_masks, \n",
    "                                        label_map, \n",
    "                                        do_shuffle = True, \n",
    "                                        balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(val_data), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(val_data, \n",
    "                                       test_label_masks, \n",
    "                                       label_map, \n",
    "                                       do_shuffle = False, \n",
    "                                       balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eee12b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  102,   165, 30135,  ...,     0,     0,     0],\n",
      "        [  102,   601,   111,  ...,     0,     0,     0],\n",
      "        [  102,  1556,  7053,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  102,  2360,   214,  ...,     0,     0,     0],\n",
      "        [  102,  3751,   111,  ...,     0,     0,     0],\n",
      "        [  102,   111,  1671,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 0, 2, 1, 0, 1, 1, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 2, 1, 2, 1, 0, 0,\n",
      "        2, 0, 0, 0, 1, 0, 0, 2]), tensor([False, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True,  True, False, False,  True, False, False, False,  True, False,\n",
      "        False,  True])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cc4eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58134/1222994171.py:57: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  label_mask_array = torch.tensor(label_mask_array)\n"
     ]
    }
   ],
   "source": [
    "test_data = load_original_dataset(fold=fold, labeled=True, mode='test', percentage=percentage)\n",
    "\n",
    "test_label_masks = np.ones(len(test_data), dtype=bool)\n",
    "eval_dataloader = generate_data_loader(test_data, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8906d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "        super(Generator, self).__init__()\n",
    "        n_classes = 2\n",
    "        layers = []\n",
    "        hidden_sizes = [noise_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.label_embedding = nn.Embedding(n_classes, noise_size)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output_rep = self.layers(noise)\n",
    "        return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=4, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1], num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97740cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "generator = Generator(noise_size=noise_size, \n",
    "                      output_size=hidden_size, \n",
    "                      hidden_sizes=hidden_levels_g, \n",
    "                      dropout_rate=out_dropout_rate)\n",
    "\n",
    "discriminator = Discriminator(input_size=hidden_size, \n",
    "                              hidden_sizes=hidden_levels_d, \n",
    "                              num_labels=len(label_list), \n",
    "                              dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    transformer.cuda()\n",
    "    if multi_gpu:\n",
    "        transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f9c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run(transformer, discriminator, generator, test_dataloader):\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(weight=class_weights, ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs[-1]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    return avg_test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775f158d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:14.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:36.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:43.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:51.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:58.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:05.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:12.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:20.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:27.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:34.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:42.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:49.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:56.\n",
      "\n",
      "  Average training loss generetor: 0.692\n",
      "  Average training loss discriminator: 0.956\n",
      "  Training epcoh took: 0:02:02\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.922\n",
      "  Test Loss: 0.314\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:51.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:58.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:13.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:20.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:28.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:35.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:42.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:50.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:57.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.717\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.933\n",
      "  Test Loss: 0.405\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:51.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:28.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:50.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.713\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.911\n",
      "  Test Loss: 0.457\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:52.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:28.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:51.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.704\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.933\n",
      "  Test Loss: 0.608\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:52.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:28.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:51.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.702\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.933\n",
      "  Test Loss: 0.544\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:30.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:52.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:28.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:51.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.700\n",
      "  Average training loss discriminator: 0.721\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.933\n",
      "  Test Loss: 0.539\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:51.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:28.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:50.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.709\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.956\n",
      "  Test Loss: 0.344\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:30.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:52.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:29.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:51.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.700\n",
      "  Training epcoh took: 0:02:03\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.956\n",
      "  Test Loss: 0.405\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:30.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   140  of    335.    Elapsed: 0:00:52.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:29.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:44.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:51.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.698\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.956\n",
      "  Test Loss: 0.466\n",
      "  Test took: 0:00:00\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    335.    Elapsed: 0:00:07.\n",
      "  Batch    40  of    335.    Elapsed: 0:00:15.\n",
      "  Batch    60  of    335.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    335.    Elapsed: 0:00:30.\n",
      "  Batch   100  of    335.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    335.    Elapsed: 0:00:44.\n",
      "  Batch   140  of    335.    Elapsed: 0:00:52.\n",
      "  Batch   160  of    335.    Elapsed: 0:00:59.\n",
      "  Batch   180  of    335.    Elapsed: 0:01:07.\n",
      "  Batch   200  of    335.    Elapsed: 0:01:14.\n",
      "  Batch   220  of    335.    Elapsed: 0:01:21.\n",
      "  Batch   240  of    335.    Elapsed: 0:01:29.\n",
      "  Batch   260  of    335.    Elapsed: 0:01:36.\n",
      "  Batch   280  of    335.    Elapsed: 0:01:43.\n",
      "  Batch   300  of    335.    Elapsed: 0:01:51.\n",
      "  Batch   320  of    335.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.699\n",
      "  Training epcoh took: 0:02:04\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.956\n",
      "  Test Loss: 0.526\n",
      "  Test took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "training_stats = []\n",
    "loss_logs = []\n",
    "eval_results = []\n",
    "test_results = []\n",
    "n_classes = 2\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = [v for v in discriminator.parameters()]\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW([\n",
    "                    {'params': transformer_vars, 'lr': 2e-5}, \n",
    "                    {'params': d_vars, 'lr': learning_rate_discriminator}\n",
    "                ],eps=1e-8, betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "\n",
    "gen_optimizer = torch.optim.AdamW([\n",
    "                    {'params': g_vars, 'lr': learning_rate_generator}, \n",
    "                ],eps=1e-8, betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "    num_train_examples = len(train_examples)\n",
    "    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "    scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "    scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "label_int = np.array([data.item() for array in train_dataloader for data in array[2]])\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(label_int), y=label_int)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
    "\n",
    "transformer_path = f'./models/GAN_SciBERT_Transformer_original_fold_{fold}.h5'\n",
    "discriminator_path = f'./models/GAN_SciBERT_Discriminator_original_fold_{fold}.h5'\n",
    "best_accuracy = 0\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs[-1]\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        # label_batch = np.array([data.item() for data in batch[2]])\n",
    "        # cw = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(label_batch), y=label_batch)\n",
    "\n",
    "#         count = Counter(batch[2].numpy())\n",
    "#         count_0 = count.get(0)\n",
    "#         count_1 = count.get(1)\n",
    "#         if count_0 == None:\n",
    "#             count_0 = 0\n",
    "#         if count_1 == None:\n",
    "#             count_1 = 0\n",
    "#         class_count = np.array([count_0, count_1])\n",
    "#         class_weight = class_count/sum(class_count)\n",
    "        \n",
    "        # gen_weights = np.random.choice([0, 1], size=real_batch_size, p=cw)\n",
    "        # gen_labels = torch.tensor(gen_weights, dtype=torch.long, device=device)\n",
    "        noise = torch.randn(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # gen_labels = torch.randint(0, n_classes, (real_batch_size,), dtype=torch.long, device=device)\n",
    "        # noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        gen_rep = generator(noise)\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        label2one_hot_with_weight = class_weights * label2one_hot\n",
    "        per_example_loss = -torch.sum(label2one_hot_with_weight * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "            D_L_Supervised = 0\n",
    "        else:\n",
    "            D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "        \n",
    "        loss_logs.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'step': step + 1,\n",
    "                'G_feature_matching': g_feat_reg,\n",
    "                'G_Unsupervised': g_loss_d,\n",
    "                'D_Supervised': D_L_Supervised,\n",
    "                'D_Unsupervised': D_L_unsupervised1U + D_L_unsupervised2U\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "            scheduler_d.step()\n",
    "            scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    avg_test_loss, test_accuracy = test_run(transformer, discriminator, generator, test_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if test_accuracy >= best_accuracy:\n",
    "        torch.save(transformer.state_dict(), transformer_path)\n",
    "        torch.save(discriminator.state_dict(), discriminator_path)\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fc69144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss generator</th>\n",
       "      <th>Training Loss discriminator</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Test Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692418</td>\n",
       "      <td>0.955997</td>\n",
       "      <td>0.313910</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0:02:02</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702606</td>\n",
       "      <td>0.717218</td>\n",
       "      <td>0.405168</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700252</td>\n",
       "      <td>0.713248</td>\n",
       "      <td>0.457139</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.699581</td>\n",
       "      <td>0.703718</td>\n",
       "      <td>0.607808</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.700747</td>\n",
       "      <td>0.702031</td>\n",
       "      <td>0.543794</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.700416</td>\n",
       "      <td>0.721169</td>\n",
       "      <td>0.538704</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.698580</td>\n",
       "      <td>0.709419</td>\n",
       "      <td>0.344318</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.698499</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0:02:03</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.698129</td>\n",
       "      <td>0.699493</td>\n",
       "      <td>0.465780</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0:02:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.698694</td>\n",
       "      <td>0.698898</td>\n",
       "      <td>0.525737</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0:02:04</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss generator  Training Loss discriminator  Valid. Loss  \\\n",
       "epoch                                                                      \n",
       "1                     0.692418                     0.955997     0.313910   \n",
       "2                     0.702606                     0.717218     0.405168   \n",
       "3                     0.700252                     0.713248     0.457139   \n",
       "4                     0.699581                     0.703718     0.607808   \n",
       "5                     0.700747                     0.702031     0.543794   \n",
       "6                     0.700416                     0.721169     0.538704   \n",
       "7                     0.698580                     0.709419     0.344318   \n",
       "8                     0.698499                     0.700195     0.405360   \n",
       "9                     0.698129                     0.699493     0.465780   \n",
       "10                    0.698694                     0.698898     0.525737   \n",
       "\n",
       "       Valid. Accur. Training Time Test Time  \n",
       "epoch                                         \n",
       "1           0.922222       0:02:02   0:00:00  \n",
       "2           0.933333       0:02:03   0:00:00  \n",
       "3           0.911111       0:02:03   0:00:00  \n",
       "4           0.933333       0:02:03   0:00:00  \n",
       "5           0.933333       0:02:03   0:00:00  \n",
       "6           0.933333       0:02:03   0:00:00  \n",
       "7           0.955556       0:02:03   0:00:00  \n",
       "8           0.955556       0:02:03   0:00:00  \n",
       "9           0.955556       0:02:04   0:00:00  \n",
       "10          0.955556       0:02:04   0:00:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = pd.DataFrame(training_stats)\n",
    "df_stats.set_index('epoch', inplace=True)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43169429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "plt.plot(df_stats['Training Loss generator'], 'b-o', label='Generator Loss')\n",
    "plt.plot(df_stats['Training Loss discriminator'], 'g-o', label='Discriminator Loss')\n",
    "plt.plot(df_stats['Valid. Loss'], 'r-o', label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xticks(df_stats.index)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "164c5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31091, 768)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_transformer = BertModel.from_pretrained(model_name)\n",
    "best_transformer.resize_token_embeddings(len(tokenizer))\n",
    "best_transformer.load_state_dict(torch.load(transformer_path))\n",
    "best_transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea33ace8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logit): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "best_discriminator.load_state_dict(torch.load(discriminator_path))\n",
    "best_discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab12042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_bert_predict(transformer, discriminator, test_dataloader):\n",
    "    \n",
    "    transformer.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "    all_filtered_logits = []\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs[-1]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            \n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "        all_filtered_logits += filtered_logits.detach().cpu()\n",
    "        \n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    all_filtered_logits = torch.stack(all_filtered_logits).numpy()\n",
    "    \n",
    "    return all_labels_ids, all_preds, all_filtered_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e56ab0b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.38636%\n",
      "Precision: 81.99437%\n",
      "Recall: 79.50880%\n",
      "F1 Score: 80.67994%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  NOTUTILIZE      0.952     0.963     0.957       778\n",
      "     UTILIZE      0.688     0.627     0.656       102\n",
      "\n",
      "    accuracy                          0.924       880\n",
      "   macro avg      0.820     0.795     0.807       880\n",
      "weighted avg      0.921     0.924     0.922       880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_true, y_pred, probs = gan_bert_predict(best_transformer, best_discriminator, eval_dataloader)\n",
    "\n",
    "usage_class_names = ['EXTEND', 'MENTION', 'NOTALGO', 'USE']\n",
    "utilize_class_labels = [\"NOTUTILIZE\", \"UTILIZE\"]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print('Accuracy: %.5f%%' % (accuracy*100))\n",
    "print('Precision: %.5f%%' % (precision*100))\n",
    "print('Recall: %.5f%%' % (recall*100))\n",
    "print('F1 Score: %.5f%%' % (f1*100))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=utilize_class_labels, zero_division=0, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e500dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 2]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cf2cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# evaluate_roc(probs, y_true-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36559acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[733  45]\n",
      " [ 11  91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c62742d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(utilize_class_labels)\n",
    "ax.yaxis.set_ticklabels(utilize_class_labels)\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf776a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_encoding = {v: k for k, v in label_map.items()}\n",
    "pred_label = [inv_encoding[key] for key in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b59784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_dataset(fold=1, percentage=None):\n",
    "    df = pd.read_csv(f'../spin-off/dataset/fold_{fold}/10-fold_original_{percentage}/algocite_utilize_dataset_test_fold_{fold}.csv')\n",
    "    df['CITATIONS_CONTEXTS'] = df['CITATIONS_CONTEXTS'].str.replace(r\"=-=[\\S\\s]+-=-\", \"<cite>\", regex=True)\n",
    "    X, y = df['CITATIONS_CONTEXTS'].values, df['UTILIZE_LABELS'].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d2cc17f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITATIONS_CONTEXTS</th>\n",
       "      <th>UTILIZE_LABELS</th>\n",
       "      <th>PRED_LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he content of each pixel. These kinds of algor...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iagram. The proposed model includes validation...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plicity intervals are not redefined. We consid...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y many prunings, a recent method developed in ...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on fault detectability [23]. A clock partition...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>s in the barycentric Bernstein basis can be so...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>UTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>[20], and the controller is calculated automat...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>o be as large as the theoretical step. 4.4 Pol...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>or vice versa. To aid in understanding the co-...</td>\n",
       "      <td>UTILIZE</td>\n",
       "      <td>UTILIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>on. Again, the difference in performance is la...</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "      <td>NOTUTILIZE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>880 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    CITATIONS_CONTEXTS UTILIZE_LABELS  \\\n",
       "0    he content of each pixel. These kinds of algor...     NOTUTILIZE   \n",
       "1    iagram. The proposed model includes validation...     NOTUTILIZE   \n",
       "2    plicity intervals are not redefined. We consid...     NOTUTILIZE   \n",
       "3    y many prunings, a recent method developed in ...     NOTUTILIZE   \n",
       "4    on fault detectability [23]. A clock partition...     NOTUTILIZE   \n",
       "..                                                 ...            ...   \n",
       "875  s in the barycentric Bernstein basis can be so...     NOTUTILIZE   \n",
       "876  [20], and the controller is calculated automat...     NOTUTILIZE   \n",
       "877  o be as large as the theoretical step. 4.4 Pol...     NOTUTILIZE   \n",
       "878  or vice versa. To aid in understanding the co-...        UTILIZE   \n",
       "879  on. Again, the difference in performance is la...     NOTUTILIZE   \n",
       "\n",
       "    PRED_LABELS  \n",
       "0    NOTUTILIZE  \n",
       "1    NOTUTILIZE  \n",
       "2    NOTUTILIZE  \n",
       "3    NOTUTILIZE  \n",
       "4    NOTUTILIZE  \n",
       "..          ...  \n",
       "875     UTILIZE  \n",
       "876  NOTUTILIZE  \n",
       "877  NOTUTILIZE  \n",
       "878     UTILIZE  \n",
       "879  NOTUTILIZE  \n",
       "\n",
       "[880 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = load_eval_dataset(fold=fold, percentage=percentage)\n",
    "df_test = pd.DataFrame({'CITATIONS_CONTEXTS': X_test, 'UTILIZE_LABELS': y_test, 'PRED_LABELS': pred_label})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4dd0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(f'./cls_results/GAN_SciBERT_original_UTILIZE_{percentage}_Fold_{fold}_100_unlabeled_new2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe63b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776dcde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78a3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2bb404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
